# Global imports
import os
import re
import argparse
import pandas as pd
from Bio import SeqIO
from datetime import datetime

# Script information - Written in Python 3.9.12 - May 2023
__author__ = "Guillermo Carrillo Martin"
__maintainer__ = "Guillermo Carrillo Martin"
__email__ = "guillermo.carrillo@upf.edu"

"""
This script generates metadata files with information about a multi-fasta protein database,
outputted from the uniparc_download.py script.

Six (or seven if gene list) metadata files are generated by this script:

1. summary.txt; A text file with a summary of all the metadata information retrieved 
   from the multi-fasta database. It also shows the paths to all the other files.

2. genes_NOT_retrieved.txt; A text file that contains the genes not retrieved. This
   file is only created if the list of genes used to build the multi-fasta is 
   specified.

3. records_info.csv; A CSV file that contains all the information present in each 
   record header. See the README.md file for a detailed description of the header 
   information.

4. genes_retrieved.csv; A CSV file that contains the number of genes retrieved.

5. species_retrieved.csv; A CSV file that contains the number of species retrieved, 
   indicating the scientific name and the TaxID.

6. repositories_employed.csv; A CSV file that contains the number of the different
   sources (repositories) used to build the multi-fasta. 

7. species_genes.csv; A CSV file that shows the number of genes retrieved for each 
   species.
"""
def main():

  print("# Generating metadata information")
  database_path, metadata_folder_path, tax_id, gene_list_path = parser()

  # Create a folder to store metadata information
  if not os.path.exists(metadata_folder_path):    
      os.mkdir(metadata_folder_path)

  # Create a dataframe with all the info per record and write it as csv
  record_info_df = write_records_info_csv(database_path, metadata_folder_path)

  # If a gene list was inputed, write the 'genes-not-recoverd' list
  if gene_list_path:
    gene_search_count = write_genes_not_retrieved_txt(record_info_df, gene_list_path, metadata_folder_path)
  elif not gene_list_path:
    gene_search_count = None    

  # Write the 'count' csv files
  genes_retrieved_count = write_genes_retrieved_csv(record_info_df, metadata_folder_path)
  repositories_total_count = write_repositories_employed_csv(record_info_df, metadata_folder_path)
  species_total_count = write_species_retrieved_csv(record_info_df, metadata_folder_path)
  write_species_per_gene_csv(record_info_df, metadata_folder_path)
    
  # Write the summary.txt file
  write_summary_txt(database_path, metadata_folder_path, gene_list_path, tax_id, genes_retrieved_count, gene_search_count, repositories_total_count, species_total_count)

def parser():
    """
    This function parses the required arguments from the terminal to the python script.
    
    #OUTPUT
    - database_path (string); The path to the input multi-fasta database.
    - metadata_folder_path (string); The path to a folder where the results will be stored.
    - tax_id (integer); The TaxID number employed to construct the multi-fasta database.
    - gene_list_path (string); The path to the gene list employed to construct the multi-fasta.
      database. If no gene list is specified, the variable will be assigned as None.
    """
  
    parser = argparse.ArgumentParser(description="A script that creates metadata information for a database created by uniparc_download.py")
    parser.add_argument("--input-path", dest="input_path", type=str, help="The path to the input database", required=True, nargs=1)
    parser.add_argument("--output-path", dest="output_path", type=str, help="The path to write the metadata folder (default: working directory)", required=True, default=["."], nargs=1)
    parser.add_argument("--output-folder-name", dest="output_folder_name", type=str, help="The name of the folder storing the metadata (default: metadata)", required=True, default=["metadata"], nargs=1)
    parser.add_argument("--tax-id", dest="TaxID", type=int, help="The TaxID number employed to construct the multi-fasta database", required=True, nargs=1)
    parser.add_argument("--genes", dest="gene_list", type=str, help="The path to the list of genes (not mandatory)", required=False, default=["None"], nargs=1)

    args = parser.parse_args()
  
    output_path = os.path.realpath(args.output_path[0])
    output_folder_name = args.output_folder_name[0]
    
    metadata_folder_path = f"{output_path}/{output_folder_name}"
    database_path = os.path.realpath(args.input_path[0])
    tax_id = args.TaxID[0]

    if args.gene_list[0] != "None":
        gene_list_path = os.path.realpath((args.gene_list[0]))
    if args.gene_list[0] == "None":
        gene_list_path = None

    return database_path, metadata_folder_path, tax_id, gene_list_path

def retrieve_tag(regular_expression, header):
    """
    This function extracts a substring from a fasta header using a regular expression.
    If the expression is not fullfilled, it would return an empty string.
    
    #INPUT
    - regular_expression (string); The regular expression to select the substring.
    - header (string); A fasta header, formatted from the uniparc_download.py script.
    #OUTPUT
    - tag (String); The retrieved substring from the fasta header.
    """
    # Retrieve the tag
    tag_match = re.search(regular_expression, header)
    if tag_match:
        tag = tag_match.group(1)
    
    # If no match, retrieves the string "NA"
    elif not tag_match:
        tag = "no gene"

    return tag

def write_records_info_csv(database_path, metadata_folder_path):
    """
    This function generates a pandas dataframe were each row contains the information of a
    header from all the multi-fasta records. It also writes the dataframe as a csv file.
    
    #INPUT
    - database_path (string); The path to the multi-fasta database.
    - metadata_folder_path (string); The path to a folder where the results will be stored.
    #OUTPUT
    - record_info_df (pd.DataFrame); A dataframe containing all the information present 
      in each record header.
    #WRITE OUTPUT
    - records_info.csv; A CSV file that contains all the information present in each 
      record header. See the README.md file for a detailed description of the header 
      information.
    """
    record_info_list = []
    
    # Retrieve each tag per fasta header and store the result in a list of lists
    for record in SeqIO.parse(database_path, "fasta"):
        upi_identifier = retrieve_tag(r"\|(UPI[0-9A-Z]{10})", record.description) # UPI\d{10}\w* or UPI[0-9A-Z]{10}
        repository = retrieve_tag(r"^([^|]+)", record.description)
        gene = retrieve_tag(r"GN=(.*?)\sSV=", record.description)
        species = retrieve_tag(r"OS=(.*?)\sOX=", record.description)
        taxid = retrieve_tag(r"OX=(\w+)", record.description)
        date = retrieve_tag(r"\|([\d-]+)", record.description)
        version = retrieve_tag(r"SV=(\d+)", record.description)   

        header_info = [upi_identifier, repository, gene, species, taxid, date, version]
        record_info_list.append(header_info)

    # Generate the pandas dataframe and write the csv
    colnames = ["Unic Identifier", "Repository", "Gene", "Species", "TaxID", "Last update", "Sequence version"]
    record_info_df = pd.DataFrame(record_info_list, columns=colnames)
    record_info_df.to_csv(f"{metadata_folder_path}/records_info.csv", index=False)

    return record_info_df

def write_genes_not_retrieved_txt(record_info_df, gene_list_path, metadata_folder_path):
    """
    This function returns the number of genes indicated to focus the protein download, if 
    a gene list is inputed. It also writes the list of genes not retrieved as a text file.
    
    #INPUT
    - record_info_df (DataFrame); A dataframe containing all the information present 
      in each record header.
    - gene_list_path (string); The path to the gene list employed to construct the multi-fasta 
      database.
    - metadata_folder_path (string); The path to a folder where the results will be stored.
    #OUTPUT
    - gene_search_count (integer); The number of genes to focus the protein download.
    #WRITE OUTPUT
    - genes_NOT_retrieved.txt; A text file with all the genes not retrieved after the protein
      download.
    """
    # Append in a python list all the genes in gene_list.txt
    gene_search_list = []
    with open(gene_list_path, "rt") as gene_list_file: #Open the gene list file
        for gene in gene_list_file:
            gene_search_list.append(gene.strip().replace("\n", "")) #Append the genes in the file to a list

    # Append in a python the genes found after the protein download
    gene_found_list = list(record_info_df["Gene"].unique())

    # Compare the gene_found_list with the gene_search_list and create genes_not_found_list
    gene_not_found_ls = []
    for gene in gene_search_list:
        if gene not in gene_found_list:
            gene_not_found_ls.append(gene)

    # Write the genes not retrieved in a text file
    with open(metadata_folder_path + "/genes_NOT_retrieved.txt", "wt") as genes_not_retrieved:
        for gene in gene_not_found_ls:
            genes_not_retrieved.write(gene + "\n")
    
    # Count the number of different genes found after the protein download
    gene_search_count = len(gene_search_list)

    return gene_search_count

def write_genes_retrieved_csv(record_info_df, metadata_folder_path):
    """
    This function returns the number of genes found after the protein download. It also writes, 
    as a CSV file, the number of times each gene has been retrieved.
    
    #INPUT
    - record_info_df (DataFrame); A dataframe containing all the information present 
      in each record header.
    - metadata_folder_path (string); The path to a folder where the results will be stored.
    #OUTPUT
    - genes_retrieved_count (integer); The number of different genes found.
    #WRITE OUTPUT
    - genes_retrieved.csv; A CSV file with the number of times each different gene has been 
      found.
    """
    # Count, in a Panda series, the time each "Gene" appears in the database
    gene_retrieved_count_sr = record_info_df["Gene"].value_counts()
    gene_retrieved_count_sr.to_csv(metadata_folder_path + "/genes_retrieved.csv", index_label="Gene", header=["Count"])

    # Count the number of different genes
    if "no gene" in gene_retrieved_count_sr:
      gene_retrieved_count_sr = gene_retrieved_count_sr.drop("no gene")
    genes_retrieved_count = gene_retrieved_count_sr.count()

    return genes_retrieved_count

def write_repositories_employed_csv(record_info_df, metadata_folder_path):
    """
    This function returns the number of repositories found after the protein download. 
    It also writes, as a CSV file, the number of times each repository has been retrieved.
    
    #INPUT
    - record_info_df (DataFrame); A dataframe containing all the information present 
      in each record header.
    - metadata_folder_path (string); The path to a folder where the results will be stored.
    #OUTPUT
    - repositories_total_count (integer); The number of different repositories found.
    #WRITE OUTPUT
    - repositories_employed.csv; A CSV file with the number of times each different repository
      has been found.
    """
    # Count, in a Panda series, the time each "Repository" appears in the database
    repositories_count_sr = record_info_df["Repository"].value_counts() #A Panda series counting the values of "Repository"
    repositories_count_sr.to_csv(metadata_folder_path + "/repositories_employed.csv", index_label="Repository", header=["Count"])

    # Count the number of different repositories
    repositories_total_count = repositories_count_sr.count()

    return repositories_total_count

def write_species_retrieved_csv(record_info_df, metadata_folder_path):
    """
    This function returns the number of species found after the protein download. 
    It also writes, as a CSV file, the number of times each species has been retrieved,
    indicating also the corresponding TaxID.
    
    #INPUT
    - record_info_df (DataFrame); A dataframe containing all the information present 
      in each record header.
    - metadata_folder_path (string); The path to a folder where the results will be stored.
    #OUTPUT
    - species_total_count (integer); The number of different species found.
    #WRITE OUTPUT
    - species_retrieved.csv; A CSV file with the number of times each different species
      has been found, with its corresponding TaxID.
    """
    # Count, in a Panda series, the time each "Species-TaxID" appears in the database
    species_count_sr = record_info_df[["Species", "TaxID"]].value_counts()
    species_count_sr.to_csv(metadata_folder_path + "/species_retrieved.csv", index_label=["Species", "TaxID"], header=["Count"])

    # Count the number of different species
    species_total_count = species_count_sr.count()

    return species_total_count

def write_species_per_gene_csv(record_info_df, metadata_folder_path):
    """
    This function writes, as a CSV file, the number of times each gene has been found in each species.
    In other words, it counts the number of times per each gene-species combination.
    
    #INPUT
    - record_info_df (DataFrame); A dataframe containing all the information present 
      in each record header.
    - metadata_folder_path (string); The path to a folder where the results will be stored.
    #WRITE OUTPUT
    - species_genes.csv; A CSV file with the number of times each different gene-species 
      combination has been found.
    """
    
    # Calculate the count per each gene and species combination
    species_gene_df = record_info_df.groupby(["Gene", "Species"]).size().reset_index(name="Count")
    
    # Sort and reorder the possition of the columns
    species_gene_df.sort_values(["Species", "Count"], axis=0,ascending=[True, False], inplace=True)
    species_gene_df = species_gene_df.loc[:, ["Species", "Gene", "Count"]] # Reorder the columns

    # Write the dataframe as a csv
    species_gene_df.to_csv(f"{metadata_folder_path}/species_genes.csv", index=False)

def write_summary_txt(database_path, metadata_folder_path, gene_list_path, tax_id, genes_retrieved_count, gene_search_count, repositories_total_count, species_total_count):
  """
  This function writes a summary of all the metadata in a text file. It also writes a serie
  of errors in the file if some conditions are fulfilled, like the absence of gene name in a 
  header. 
  
  #INPUT
  - database_path (string); The path to the multi-fasta database.
  - metadata_folder_path (string); The path to a folder where the results will be stored.
  - gene_list_path (string); The path to the gene list employed to construct the multi-fasta.
  - tax_id (integer); The TaxID number employed to construct the multi-fasta database.
  - genes_retrieved_count (integer); The number of different genes found.
  - gene_search_count (integer); The number of genes to focus the protein download.
  - repositories_total_count (integer); The number of different repositories found.
  - species_total_count (integer); The number of different species found.
  #WRITE OUPUT
  - summary.txt; A text file with a summary of all the metadata information retrieved 
    from the multi-fasta database. It also shows the paths to all the other files.
  """
  with open(metadata_folder_path + "/summary.txt", "wt") as metadata:

    # Metadata general information 
    metadata.write(f"## METADATA for the database {database_path}\n")
    metadata.write(f"TaxID: {tax_id}\n")
    
    if gene_list_path:
        metadata.write(f"Gene list: {gene_list_path}\n")
    
    # Current time and date
    current_date_time = datetime.now()
    date_time = current_date_time.strftime("%d/%m/%Y - %H:%M:%S")
    metadata.write(f"{date_time}\n" + "\n")

    # Disclaimer
    metadata.write("# DISCLAIMER\n")
    metadata.write("Information present in metadata files can be underestimated due to UniParc's non-redundant architecture. Evolutionarily conserved proteins will appear only once in UniParc, which biases the number of species recovered. This is also the case for two proteins present in different repositories, as the metadata information will be merged in one UniParc record. That is why we recommend the user to take the metadata information as the minimum knowledge of the database.\n\n")

    # Warnings
    warnings = 0
    record_num = os.popen(f"grep -E -c '^>' {database_path}").read()
    metadata.write("# WARNINGS\n")

    record_with_gene = os.popen(f"cat {database_path} | grep -E '^>' | grep -c 'GN='").read()
    if record_num != record_with_gene: # Not all the headers have a gene name
        warnings += 1
        metadata.write("Check gene names (GN=)\n")
    
    record_with_taxname = os.popen(f"cat {database_path} | grep -E '^>' | grep -c 'OS='").read()
    if record_num != record_with_taxname: # Not all the headers have a species tag
        warnings += 1
        metadata.write("Check taxa names (OS=)\n")

    record_with_taxid = os.popen(f"cat {database_path} | grep -E '^>' | grep -c 'OX='").read()
    if record_num != record_with_taxid: # Not all the headers have a TaxID
        warnings += 1
        metadata.write("Check taxIDs (OX=)\n")

    if gene_list_path:
        if genes_retrieved_count != gene_search_count: # Not all the search genes have been retrieved
            warnings += 1
            metadata.write(f"{(gene_search_count) - (genes_retrieved_count)} genes not found\n")

    if warnings == 0:
        metadata.write("No warnings\n")

    # Stats about the protein records
    metadata.write("\n# Stats about the protein records\n" + \
                    "records: {}".format(record_num) + \
                    "records_with_gene: {}/{}".format(record_with_gene[:-1],record_num) + \
                    "records_with_taxname: {}/{}".format(record_with_taxname[:-1],record_num) + \
                    "records_with_taxid: {}/{}".format(record_with_taxid[:-1],record_num) + 
                    "all_records_path: {}\n".format(metadata_folder_path + "/records_info.csv"))

    # Stats about the employed repositories
    metadata.write("\n# Stats about the employed repositories\n" + \
                    "repositories_employed: {}\n".format(repositories_total_count) + \
                    "repositories_employed_path: {}\n\n".format(metadata_folder_path + "/repositories_employed.csv"))

    # Stats about the genes found
    if gene_list_path:            
        metadata.write("# Stats about the genes found\n" + \
                        "genes_retrieved: {}/{}\n".format(genes_retrieved_count,gene_search_count) + \
                        "genes_retrieved_path: {}\n".format(metadata_folder_path + "/genes_retrieved.csv") + \
                        "genes_not_retrieved_path: {}\n".format(metadata_folder_path + "/genes_NOT_retrieved.txt"))
    
    elif not gene_list_path:
        metadata.write("# Stats about the genes found\n" + \
                        "genes_retrieved: {}\n".format(genes_retrieved_count) + \
                        "genes_retrieved_path: {}\n".format(metadata_folder_path + "/genes_retrieved.csv"))

    #  Stats about the species in the database
    metadata.write("\n# Stats about the species in the database\n" + \
                    "species_retrieved: {}\n".format(species_total_count) + \
                    "species_retrieved_path: {}\n".format(metadata_folder_path + "/species_retrieved.csv") + \
                    "species_and_genes_path: {}".format(metadata_folder_path + "/species_genes.csv"))

main()